#!/usr/bin/env python3
"""
Database Migration Helper for MagFlow ERP

This script generates and applies database migrations based on schema validation results.
It provides a safe way to update database schemas with proper rollback capabilities.

Usage:
    python3 -m app.core.migration_helper
    python3 migration_helper.py --validate-only
    python3 migration_helper.py --apply-migrations
"""

import argparse
import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path

# Add the app directory to the Python path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from app.core.database_resilience import DatabaseConfig
from app.core.schema_validator import print_validation_report, validate_sync_environment

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class MigrationHelper:
    """Helper class for generating and applying database migrations."""

    # Define proper column types for different databases
    COLUMN_TYPES = {
        "id": "SERIAL PRIMARY KEY",
        "customer_id": "INTEGER",
        "order_date": "TIMESTAMP",
        "status": "VARCHAR(50)",
        "total_amount": "DECIMAL(10,2)",
        "external_id": "VARCHAR(255)",
        "external_source": "VARCHAR(50)",
        "created_at": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP",
        "updated_at": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP",
        "product_id": "INTEGER",
        "quantity": "INTEGER",
        "unit_price": "DECIMAL(10,2)",
        "name": "TEXT",
        "sku": "VARCHAR(255)",
        "price": "DECIMAL(10,2)",
        "stock": "INTEGER",
        "is_active": "BOOLEAN DEFAULT TRUE",
        "emag_product_id": "VARCHAR(255)",
        "emag_offer_id": "VARCHAR(255)",
        "account_type": "VARCHAR(20)",
        "category_id": "VARCHAR(255)",
        "brand": "TEXT",
        "sync_timestamp": "TIMESTAMP",
        "products_count": "INTEGER",
        "offers_count": "INTEGER",
        "error_message": "TEXT",
    }

    # Required columns for each table (matching SchemaValidator)
    REQUIRED_COLUMNS = {
        "orders": {
            "id",
            "customer_id",
            "order_date",
            "status",
            "total_amount",
            "external_id",
            "external_source",
            "created_at",
            "updated_at",
        },
        "order_lines": {"id", "order_id", "product_id", "quantity", "unit_price"},
        "products": {"id", "name", "sku", "price", "stock", "is_active"},
        "emag_products": {
            "id",
            "emag_product_id",
            "account_type",
            "name",
            "sku",
            "price",
            "stock",
            "category_id",
            "brand",
        },
        "emag_product_offers": {
            "id",
            "emag_offer_id",
            "account_type",
            "emag_product_id",
            "name",
            "sku",
            "price",
            "stock",
        },
        "emag_offer_syncs": {
            "id",
            "account_type",
            "sync_timestamp",
            "products_count",
            "offers_count",
            "status",
            "error_message",
        },
    }

    def __init__(self):
        self.db_config = DatabaseConfig()
        self.migration_dir = Path(__file__).parent.parent / "migrations"

    def generate_migration_sql(self, missing_columns: dict[str, list[str]]) -> str:
        """
        Generate SQL migration script for missing columns.

        Args:
            missing_columns: Dict mapping table names to missing column lists

        Returns:
            SQL migration script as string
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        migration_name = f"add_missing_columns_{timestamp}"

        sql_parts = []
        sql_parts.append(f"-- Migration: {migration_name}")
        sql_parts.append("-- Generated by MagFlow ERP Migration Helper")
        sql_parts.append(f"-- Generated at: {datetime.now().isoformat()}")
        sql_parts.append("")
        sql_parts.append(
            "-- This migration adds missing columns detected by schema validation"
        )
        sql_parts.append("-- Run this migration to fix database schema issues")
        sql_parts.append("")
        sql_parts.append("-- To apply this migration:")
        sql_parts.append(
            "-- psql -h <host> -U <user> -d <database> -f migration_file.sql"
        )
        sql_parts.append("")
        sql_parts.append("BEGIN;")
        sql_parts.append("")

        for table_name, missing_cols in missing_columns.items():
            if not missing_cols:
                continue

            sql_parts.append(f"-- Adding missing columns to {table_name}")
            for col in missing_cols:
                col_type = self.COLUMN_TYPES.get(col, "TEXT")
                sql_parts.append(
                    f"ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS {col} {col_type};"
                )

            sql_parts.append("")

        sql_parts.append("-- Create indexes for performance")
        sql_parts.append("-- Index for orders.external_id lookup")
        sql_parts.append(
            "CREATE INDEX IF NOT EXISTS idx_orders_external_id ON orders(external_id);"
        )
        sql_parts.append("-- Index for orders.external_source lookup")
        sql_parts.append(
            "CREATE INDEX IF NOT EXISTS idx_orders_external_source ON orders(external_source);"
        )
        sql_parts.append("-- Index for emag_products lookup")
        sql_parts.append(
            "CREATE INDEX IF NOT EXISTS idx_emag_products_account_sku ON emag_products(account_type, sku);"
        )
        sql_parts.append("-- Index for emag_product_offers lookup")
        sql_parts.append(
            "CREATE INDEX IF NOT EXISTS idx_emag_offers_account_sku ON emag_product_offers(account_type, sku);"
        )
        sql_parts.append("")

        sql_parts.append("COMMIT;")
        sql_parts.append("")
        sql_parts.append("-- Migration completed successfully!")

        return "\n".join(sql_parts)

    def generate_rollback_sql(self, migration_file: str) -> str:
        """
        Generate rollback SQL for a migration file.

        Args:
            migration_file: Path to the migration file

        Returns:
            SQL rollback script as string
        """
        # This would parse the migration file and generate appropriate DROP statements
        # For now, return a template
        return f"""-- Rollback script for {migration_file}
-- This script removes columns added by the migration
-- WARNING: This will permanently delete data!

BEGIN;

-- Remove added columns (be careful with this!)
-- ALTER TABLE orders DROP COLUMN IF EXISTS external_id CASCADE;
-- ALTER TABLE orders DROP COLUMN IF EXISTS external_source CASCADE;

-- Remove indexes
DROP INDEX IF EXISTS idx_orders_external_id;
DROP INDEX IF EXISTS idx_orders_external_source;
DROP INDEX IF EXISTS idx_emag_products_account_sku;
DROP INDEX IF EXISTS idx_emag_offers_account_sku;

COMMIT;

-- Rollback completed!"""

    def save_migration_file(
        self, sql_content: str, filename: str | None = None
    ) -> str:
        """
        Save migration SQL to a file.

        Args:
            sql_content: SQL content to save
            filename: Optional filename (generated if not provided)

        Returns:
            Path to the saved file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"migration_{timestamp}.sql"

        # Create migrations directory if it doesn't exist
        self.migration_dir.mkdir(exist_ok=True)

        filepath = self.migration_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(sql_content)

        logger.info(f"Migration file saved to: {filepath}")
        return str(filepath)

    async def generate_migration(self, apply_migration: bool = False) -> str:
        """
        Generate migration based on current schema validation.

        Args:
            apply_migration: Whether to apply the migration immediately

        Returns:
            Path to the generated migration file
        """
        try:
            # Get database engine for validation
            engine = self.db_config.create_optimized_engine()
            logger.info(f"Created database engine: {type(engine)}")

            if engine is None:
                raise ValueError("Failed to create database engine")

            # For schema validation, we need to create a session factory
            from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker

            async_session_factory = async_sessionmaker(
                engine, class_=AsyncSession, expire_on_commit=False
            )

            # Run schema validation
            validation_results = await validate_sync_environment(async_session_factory)
            logger.info(f"Validation results: {validation_results}")

            if validation_results["schema_valid"]:
                logger.info("‚úÖ Database schema is already valid - no migration needed")
                return "No migration needed - schema is valid"

            missing_columns = validation_results["missing_columns"]
            if not missing_columns:
                logger.info("‚úÖ No missing columns detected")
                return "No migration needed"

            # Generate migration SQL
            migration_sql = self.generate_migration_sql(missing_columns)
            migration_file = self.save_migration_file(migration_sql)

            logger.info(f"üìÑ Generated migration file: {migration_file}")
            logger.info("üîß Migration includes:")
            for table, columns in missing_columns.items():
                logger.info(f"   ‚Ä¢ {table}: {len(columns)} columns")

            if apply_migration:
                logger.info("üöÄ Applying migration...")
                # Note: In a real implementation, you might want to apply the migration
                # using a database migration tool like Alembic or by executing the SQL
                logger.warning(
                    "‚ö†Ô∏è  Automatic migration application not implemented in this version"
                )
                logger.info("üí° To apply the migration manually, run:")
                logger.info(
                    f"   psql -h <host> -U <user> -d <database> -f {migration_file}"
                )

            return migration_file

        except Exception as e:
            logger.error(f"Error generating migration: {e}")
            import traceback

            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

    def create_migration_documentation(self) -> str:
        """Create documentation for the migration system."""
        doc = f"""# MagFlow ERP Database Migration Guide

## Overview
This document explains how to use the automated migration system to fix database schema issues.

## Generated Migrations
Migration files are automatically generated based on schema validation results and saved to:
`{self.migration_dir}/`

## Migration File Format
Each migration file contains:
- Column additions with proper data types
- Index creation for performance
- Safety checks (IF NOT EXISTS clauses)
- Rollback instructions

## How to Apply Migrations

### Method 1: Using psql (Recommended)
```bash
# Connect to your database
psql -h <host> -U <user> -d <database>

# Run the migration file
\\i migration_20231201_120000.sql

# Verify the changes
\\d orders
\\d emag_products
```

### Method 2: Using a Database GUI Tool
1. Open your PostgreSQL client (pgAdmin, DBeaver, etc.)
2. Connect to your MagFlow database
3. Open the migration file
4. Execute the SQL commands

## Required Columns by Table

### orders table:
{', '.join(sorted(self.REQUIRED_COLUMNS['orders']))}

### order_lines table:
{', '.join(sorted(self.REQUIRED_COLUMNS['order_lines']))}

### products table:
{', '.join(sorted(self.REQUIRED_COLUMNS['products']))}

### emag_products table:
{', '.join(sorted(self.REQUIRED_COLUMNS['emag_products']))}

### emag_product_offers table:
{', '.join(sorted(self.REQUIRED_COLUMNS['emag_product_offers']))}

### emag_offer_syncs table:
{', '.join(sorted(self.REQUIRED_COLUMNS['emag_offer_syncs']))}

## Troubleshooting

### Common Issues:
1. **Permission denied**: Ensure your database user has CREATE/ALTER privileges
2. **Column already exists**: The migration uses IF NOT EXISTS, so it's safe to run multiple times
3. **Foreign key constraints**: Add foreign key constraints after adding columns if needed

### Rollback:
Each migration file includes rollback instructions in comments.
To rollback a migration, execute the DROP statements in reverse order.

## Best Practices
1. Always backup your database before applying migrations
2. Test migrations on a development database first
3. Apply migrations during maintenance windows
4. Keep migration files for audit purposes
5. Document any manual schema changes

## Support
For issues with the migration system, check:
1. Database logs for error messages
2. Application logs in `logs/` directory
3. Schema validation reports

---
*Generated by MagFlow ERP Migration Helper*
*Last updated: {datetime.now().isoformat()}*
"""
        return doc


def main():
    """Main entry point for the migration helper."""
    parser = argparse.ArgumentParser(
        description="MagFlow ERP Database Migration Helper"
    )
    parser.add_argument(
        "--validate-only",
        action="store_true",
        help="Only run schema validation without generating migrations",
    )
    parser.add_argument(
        "--apply-migrations",
        action="store_true",
        help="Generate and apply migrations automatically",
    )
    parser.add_argument(
        "--generate-docs", action="store_true", help="Generate migration documentation"
    )
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="Set logging level",
    )

    args = parser.parse_args()

    # Configure logging
    logging.getLogger().setLevel(getattr(logging, args.log_level))

    try:
        helper = MigrationHelper()

        if args.validate_only:
            logger.info("üîç Running schema validation only...")
            # We need to create a session factory for validation
            engine = helper.db_config.create_optimized_engine()
            from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker

            async_session_factory = async_sessionmaker(
                engine, class_=AsyncSession, expire_on_commit=False
            )

            validation_results = asyncio.run(
                validate_sync_environment(async_session_factory)
            )
            print_validation_report(validation_results)

        elif args.generate_docs:
            logger.info("üìö Generating migration documentation...")
            docs = helper.create_migration_documentation()
            docs_file = helper.migration_dir / "MIGRATION_GUIDE.md"
            with open(docs_file, "w", encoding="utf-8") as f:
                f.write(docs)
            logger.info(f"üìÑ Documentation saved to: {docs_file}")

        else:
            logger.info("üîß Generating database migration...")
            migration_file = asyncio.run(
                helper.generate_migration(args.apply_migrations)
            )

            if (
                migration_file
                and migration_file != "No migration needed"
                and migration_file != "No migration needed - schema is valid"
            ):
                logger.info("‚úÖ Migration generation completed!")
                logger.info(f"üìÑ Migration file: {migration_file}")
                logger.info("üí° Next steps:")
                logger.info("   1. Review the generated migration file")
                logger.info("   2. Backup your database")
                logger.info("   3. Apply the migration to your database")
                logger.info("   4. Run the sync script again to verify it works")
            else:
                logger.info("‚úÖ No migrations needed - database schema is valid!")

    except Exception as e:
        logger.error(f"Error in migration helper: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
